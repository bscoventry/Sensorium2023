[1mdiff --git a/.gitignore b/.gitignore[m
[1mdeleted file mode 100644[m
[1mindex e69de29..0000000[m
[1mdiff --git a/LICENSE b/LICENSE[m
[1mnew file mode 100644[m
[1mindex 0000000..6fc7873[m
[1m--- /dev/null[m
[1m+++ b/LICENSE[m
[36m@@ -0,0 +1,21 @@[m
[32m+[m[32mMIT License[m
[32m+[m
[32m+[m[32mCopyright (c) 2023 Brandon Coventry[m
[32m+[m
[32m+[m[32mPermission is hereby granted, free of charge, to any person obtaining a copy[m
[32m+[m[32mof this software and associated documentation files (the "Software"), to deal[m
[32m+[m[32min the Software without restriction, including without limitation the rights[m
[32m+[m[32mto use, copy, modify, merge, publish, distribute, sublicense, and/or sell[m
[32m+[m[32mcopies of the Software, and to permit persons to whom the Software is[m
[32m+[m[32mfurnished to do so, subject to the following conditions:[m
[32m+[m
[32m+[m[32mThe above copyright notice and this permission notice shall be included in all[m
[32m+[m[32mcopies or substantial portions of the Software.[m
[32m+[m
[32m+[m[32mTHE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR[m
[32m+[m[32mIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,[m
[32m+[m[32mFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE[m
[32m+[m[32mAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER[m
[32m+[m[32mLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,[m
[32m+[m[32mOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE[m
[32m+[m[32mSOFTWARE.[m
[1mdiff --git a/README.md b/README.md[m
[1mindex c1c9e02..3330fdb 100644[m
[1m--- a/README.md[m
[1m+++ b/README.md[m
[36m@@ -1,82 +1 @@[m
[31m-<a href="https://github.com/psf/black"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg"></a>[m
[31m-[![hub](https://img.shields.io/badge/powered%20by-hub%20-ff5a1f.svg)](https://github.com/activeloopai/Hub)[m
[31m-[m
[31m-# SENSORIUM 2023 Competition[m
[31m-[m
[31m-![plot](figures/competition.png)[m
[31m-SENSORIUM is a competition on predicting large scale mouse primary visual cortex activity. We will provide large scale datasets of neuronal activity in the visual cortex of mice. Participants will train models on pairs of natural stimuli and recorded neuronal responses, and submit the predicted responses to a set of test images for which responses are withheld. [m
[31m-[m
[31m-In 2022 we used images as stimuli, in 2023 we add the time component and use videos.[m
[31m-[m
[31m-Join our challenge and compete for the best neural predictive model![m
[31m-[m
[31m-For more information about the competition, vist our [website](http://sensorium-competition.net/).[m
[31m-[m
[31m-<!-- Have a look at our [White paper on arXiv](https://arxiv.org/abs/2206.08666), which describes the dataset and competition in detail. -->[m
[31m-[m
[31m-The White paper, which describes the dataset and competition in detail will be pubished later./[m
[31m-[m
[31m-# Important Dates[m
[31m-**June 12, 2023**: Start of the competition and data release.[m
[31m-<br>**Sep 15, 2023**: Submission deadline.[m
[31m-<br>**Sep 29, 2023**: Validation of all submitted scores completed. Preliminary winners are announced. Rank 1-3 in both competition tracks are contacted to provide the code for their submission.[m
[31m-<br>**Oct 13, 2023**: Deadline for top-ranked entries to provide the code for their submission.[m
[31m-<br>**Oct 23, 2023**: Winners contacted to contribute to the competition summary write-up.[m
[31m-[m
[31m-# Starter-kit[m
[31m-[m
[31m-This is a starter kit repo. The links for data would be published upon the competition start. Participants would have access to zip archieves or to the Deep Lake dataloaders, not to store the datasets locally.[m
[31m-[m
[31m-<!-- Below we provide a step-by-step guide for getting started with the competition. -->[m
[31m-<!-- [m
[31m-## 1. Pre-requisites[m
[31m-- install [**docker**](https://docs.docker.com/get-docker/) and [**docker-compose**](https://docs.docker.com/compose/install/)[m
[31m-- install git[m
[31m-- clone the repo via `git clone https://github.com/sinzlab/sensorium.git`[m
[31m-[m
[31m-## 2. Download neural data[m
[31m-[m
[31m-You can download the data from [https://gin.g-node.org/cajal/Sensorium2022](https://gin.g-node.org/cajal/Sensorium2022) and place it in `sensorium/notebooks/data`.[m
[31m-**Note:** Downloading the files all at once as a directory does lead to unfortunate errors. Thus, all datastes have to be downloaded individually.[m
[31m-[m
[31m-## 3. Run the example notebooks[m
[31m-[m
[31m-### **Start Jupyterlab environment**[m
[31m-```[m
[31m-cd sensorium/[m
[31m-docker-compose run -d -p 10101:8888 jupyterlab[m
[31m-```[m
[31m-now, type in `localhost:10101` in your favorite browser, and you are ready to go![m
[31m- -->[m
[31m-[m
[31m-<!-- ## **Competition example notebooks** -->[m
[31m-We provide notebooks that illustrate the structure of our data, our baselines models, and how to make a submission to the competition.[m
[31m-<br>[**Dataset tutorial**](notebooks/load_data_demo.ipynb): Shows the structure of the data and how to turn it into a PyTorch DataLoader.[m
[31m-<br>[**Model tutorial**](notebooks/models_demo.ipynb): How to train and evaluate our baseline models and even more models.[m
[31m-<!-- <br>[**Submission tutorial**](notebooks/submission_tutorial/): Use our API to make a submission to our competition. -->[m
[31m-**To download data as .zip, click [here](https://gin.g-node.org/pollytur/sensorium_2023_data)**[m
[31m-[m
[31m-## Submission comments[m
[31m-[m
[31m-Participants should submit a zip file with 2 files in it : `predictions_live_main.parquet.brotli` and `predictions_final_main.parquet.brotli` for the live and final test correspondingly. For the bonus track please replace `main` with `ood` like this : `predictions_final_ood.parquet.brotli`. [m
[31m-[m
[31m-If you do not want to use API for the competition submission,here are some guides. Each file should contains 4 columns: `mouse` with the session name, `trial_indices` (like '1.npy'), `predictions`, where each entity in the predictions column is a list of lists with shape = (number or neurons, n_frames), where n_frames is the last n_frames frames for the video, excluding the first 50 frames (like for 300 frames in video we need predictions only for the last 250), and  `neuron_ids`, which is simple the order of the neurons in the predictions.[m
[31m-[m
[31m-If you use pandas, here is a toy example how to save the data:[m
[31m-[m
[31m-```[m
[31m-data = [[m
[31m-    ('mouse1', '1.npy', np.random.random((8000, 250)).tolist(), [1,2,3]),[m
[31m-    ('mouse1', '2.npy', np.random.random((8000, 250)).tolist(), [1,2,3]),[m
[31m-    ('mouse1', '3.npy', np.random.random((8000, 250)).tolist(), [1,2,3]),[m
[31m-][m
[31m-[m
[31m-[m
[31m-df = pd.DataFrame.from_records(data, columns =['mouse', 'trial_indices', 'predictions', 'neuron_ids'])[m
[31m-df = pd.concat(dataframes_pred, ignore_index=True)[m
[31m-submission_filename = f"predictions_file_{tier}_{track}_track.parquet.brotli"[m
[31m-save_path = os.path.join(path, submission_filename) if path is not None else submission_filename[m
[31m-df.to_parquet(save_path, compression='brotli', engine='pyarrow', index=False)[m
[31m-```[m
[31m-[m
[31m-If you have any questions, feel free to reach out to us (Contact section on our [website](http://sensorium-competition.net/)), or raise an issue here on GitHub![m
[32m+[m[32m# Sensorium2023[m
\ No newline at end of file[m
[1mdiff --git a/figures/competition.png b/figures/competition.png[m
[1mdeleted file mode 100644[m
[1mindex f378201..0000000[m
Binary files a/figures/competition.png and /dev/null differ
[1mdiff --git a/figures/data.png b/figures/data.png[m
[1mdeleted file mode 100644[m
[1mindex c852465..0000000[m
Binary files a/figures/data.png and /dev/null differ
[1md